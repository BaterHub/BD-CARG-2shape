{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CARG GPKG â†’ Shapefile (Open Libraries)\n",
        "Esegui questo notebook con librerie open source (GeoPandas/Fiona/Shapely/pyproj/dbfread).\n",
        "\n",
        "- Input: GeoPackage (.gpkg) CARG\n",
        "- Domini: cartella `domini/` accanto al .gpkg\n",
        "- Output: shapefile in `output/` (fallback `output_YYYYMMDD_HHMMSS` se bloccata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Requisiti\n",
        "Installa, se mancano:\n",
        "```bash\n",
        "pip install geopandas fiona shapely pyproj dbfread\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, time, re\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import fiona\n",
        "from dbfread import DBF\n",
        "\n",
        "gpkg_path = r'C:\\path\\to\\your\\data.gpkg'  # MODIFICA QUI\n",
        "workspace = os.path.dirname(os.path.abspath(gpkg_path)) if gpkg_path else os.getcwd()\n",
        "domini_dir = os.path.join(workspace, 'domini')\n",
        "output_dir = os.path.join(workspace, 'output')\n",
        "\n",
        "# Fallback output se non scrivibile\n",
        "try:\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    test = os.path.join(output_dir, f'.write_test_{int(time.time())}')\n",
        "    with open(test, 'w', encoding='utf-8') as f: f.write('ok')\n",
        "    os.remove(test)\n",
        "except Exception:\n",
        "    ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "    output_dir = os.path.join(workspace, f'output_{ts}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print('Output:', output_dir)\n",
        "layers = fiona.listlayers(gpkg_path)\n",
        "print('Layer disponibili:', layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: domini\n",
        "def load_domain_dbf(path, code_field='CODE', desc_pattern='DESC'):\n",
        "    if not os.path.exists(path):\n",
        "        return {}\n",
        "    # Prova dbfread\n",
        "    try:\n",
        "        recs = list(DBF(path, encoding='utf-8', ignore_missing_memofile=True))\n",
        "        if not recs:\n",
        "            return {}\n",
        "        # Trova campo descrizione per pattern\n",
        "        desc_field = None\n",
        "        for k in recs[0].keys():\n",
        "            if desc_pattern.upper() in k.upper():\n",
        "                desc_field = k\n",
        "                break\n",
        "        if not desc_field or code_field not in recs[0]:\n",
        "            return {}\n",
        "        m = {}\n",
        "        for r in recs:\n",
        "            c = r.get(code_field)\n",
        "            d = r.get(desc_field)\n",
        "            if c is None or d is None:\n",
        "                continue\n",
        "            d = str(d).strip()\n",
        "            m[str(c).strip()] = d\n",
        "            if isinstance(c, (int, float)):\n",
        "                m[c] = d\n",
        "        return m\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def apply_domain(df, src_col, out_col, mapping):\n",
        "    if not mapping:\n",
        "        df[out_col] = ''\n",
        "        return df\n",
        "    def map_val(v):\n",
        "        if pd.isna(v):\n",
        "            return ''\n",
        "        return mapping.get(v, mapping.get(str(v).strip(), ''))\n",
        "    df[out_col] = df[src_col].apply(map_val) if src_col in df.columns else ''\n",
        "    return df\n",
        "\n",
        "def ensure_text_len(df, cols, maxlen=254):\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(str).str.slice(0, maxlen)\n",
        "    return df\n",
        "\n",
        "def save_shp(gdf, path):\n",
        "    # Evita campi Shape_Length/Shape_Area residui\n",
        "    drop_cols = [c for c in gdf.columns if c.upper().startswith('SHAPE_')]\n",
        "    gdf = gdf.drop(columns=drop_cols, errors='ignore')\n",
        "    gdf.to_file(path, driver='ESRI Shapefile', encoding='utf-8')\n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estrai FoglioGeologico da uno dei layer\n",
        "foglio = None\n",
        "for ln in layers:\n",
        "    try:\n",
        "        g = gpd.read_file(gpkg_path, layer=ln)\n",
        "        if 'FoglioGeologico' in g.columns:\n",
        "            v = g['FoglioGeologico'].dropna().astype(str).str.strip()\n",
        "            if not v.empty:\n",
        "                foglio = v.iloc[0]\n",
        "                break\n",
        "    except Exception:\n",
        "        pass\n",
        "assert foglio is not None, 'FoglioGeologico non trovato'\n",
        "print('Foglio:', foglio)\n",
        "# Opzionale: mappa foglio via dominio\n",
        "foglio_map = load_domain_dbf(os.path.join(domini_dir,'d_foglio.dbf'), code_field='N1', desc_pattern='N2')\n",
        "foglio_txt = foglio_map.get(foglio, foglio)\n",
        "print('Foglio (mappato):', foglio_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurazioni minime per i layer principali\n",
        "configs = {\n",
        " 'ST010Point': {\n",
        "   'search': ['ST010Point','main.ST010Point'],\n",
        "   'output': 'geomorfologia_punti.shp',\n",
        "   'fields': {'Pun_Gmo':'Pun_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_10_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')}\n",
        " },\n",
        " 'ST011Polygon': {\n",
        "   'search': ['ST011Polygon','main.ST011Polygon'],\n",
        "   'output': 'geomorfologia_poligoni.shp',\n",
        "   'fields': {'Pol_Gmo':'Pol_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_11_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')}\n",
        " },\n",
        " 'ST012Polyline': {\n",
        "   'search': ['ST012Polyline','main.ST012Polyline'],\n",
        "   'output': 'geomorfologia_linee.shp',\n",
        "   'fields': {'Lin_Gmo':'Lin_Gmo','Label':'Label','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_12_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')}\n",
        " },\n",
        " 'ST013Point': {\n",
        "   'search': ['ST013Point','main.ST013Point'],\n",
        "   'output': 'risorse_prospezioni.shp',\n",
        "   'fields': {'Num_Ris':'Num_Ris','Label1':'Label1','Label2':'Label2','Label3':'Label3','TIPO':'Tipo'},\n",
        "   'domains': {'Tipo': ('d_13_tipo.dbf','Tipo_txt')}\n",
        " },\n",
        " 'ST018Polyline': {\n",
        "   'search': ['ST018Polyline','main.ST018Polyline'],\n",
        "   'output': 'geologia_linee.shp',\n",
        "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Contorno':'Contorno','Affiora':'Affiora','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_geo': ('d_st018_line.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Contorno':('d_st018_contorno.dbf','Cont_txt'),'Affiora':('d_st018_affiora.dbf','Affior_txt')},\n",
        "   'extra_fixed': {'Fase_txt':'non applicabile/non classificabile'}\n",
        " },\n",
        " 'ST018Polygon': {\n",
        "   'search': ['ST018Polygon','main.ST018Polygon'],\n",
        "   'output': 'geologia_poligoni.shp',\n",
        "   'fields': {'Pol_Uc':'Pol_Uc','Uc_Lege':'Uc_Lege','Direzio':'Direzione'},\n",
        "   'domains': {}\n",
        " },\n",
        " 'ST019Point': {\n",
        "   'search': ['ST019Point','main.ST019Point'],\n",
        "   'output': 'geologia_punti.shp',\n",
        "   'fields': {'Num_Oss':'Num_Oss','Quota':'Quota','Inclina':'Inclinaz','Immersio':'Immersione','Direzio':'Direzione','Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Verso':'Verso','Asimmetria':'Asimmetria'},\n",
        "   'domains': {'Tipo_geo': ('d_19_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt'),'Verso':('d_verso.dbf','Verso_txt'),'Asimmetria':('d_asimmetria.dbf','Asimm_txt')}\n",
        " },\n",
        " 'ST021Polyline': {\n",
        "   'search': ['ST021Polyline','main.ST021Polyline'],\n",
        "   'output': 'geologia_linee_pieghe.shp',\n",
        "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_geo': ('d_st021.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt')},\n",
        "   'extra_fixed': {'Affior_txt':'non applicabile','Cont_txt':'no'}\n",
        " }\n",
        "}\n",
        "\n",
        "def find_layer(name_variants):\n",
        "    for nv in name_variants:\n",
        "        if nv in layers:\n",
        "            return nv\n",
        "    # fallback: match parziale\n",
        "    for nv in name_variants:\n",
        "        for L in layers:\n",
        "            if nv.lower() in L.lower():\n",
        "                return L\n",
        "    return None\n",
        "\n",
        "def process_one(cfg):\n",
        "    ln = find_layer(cfg['search'])\n",
        "    if not ln:\n",
        "        return False\n",
        "    g = gpd.read_file(gpkg_path, layer=ln)\n",
        "    # Rinomina/copia campi\n",
        "    out = pd.DataFrame(index=g.index)\n",
        "    for src,dst in cfg['fields'].items():\n",
        "        out[dst] = g[src] if src in g.columns else ''\n",
        "    # Aggiungi extra fissi e Foglio\n",
        "    for k,v in cfg.get('extra_fixed',{}).items(): out[k] = v\n",
        "    out['Foglio'] = foglio_txt\n",
        "    # Applica domini\n",
        "    for src,(domfile,target) in cfg.get('domains',{}).items():\n",
        "        dom = load_domain_dbf(os.path.join(domini_dir, domfile))\n",
        "        mapped_src = cfg['fields'].get(src, src)\n",
        "        if mapped_src in out.columns:\n",
        "            out = apply_domain(out, mapped_src, target, dom)\n",
        "    # Unisci con geometria\n",
        "    g_out = gpd.GeoDataFrame(out, geometry=g.geometry, crs=g.crs)\n",
        "    g_out = ensure_text_len(g_out, [c for c in g_out.columns if c!='geometry'])\n",
        "    save_shp(g_out, os.path.join(output_dir, cfg['output']))\n",
        "    return True\n",
        "\n",
        "processed = 0\n",
        "for k,cfg in configs.items():\n",
        "    ok = process_one(cfg)\n",
        "    if ok: processed += 1\n",
        "print('Layer processati:', processed)\n",
        "\n",
        "# Append pieghe alle linee\n",
        "pieghe = os.path.join(output_dir, 'geologia_linee_pieghe.shp')\n",
        "linee = os.path.join(output_dir, 'geologia_linee.shp')\n",
        "if os.path.exists(pieghe) and os.path.exists(linee):\n",
        "    gL = gpd.read_file(linee)\n",
        "    gP = gpd.read_file(pieghe)\n",
        "    gM = pd.concat([gL, gP], ignore_index=True)\n",
        "    gM.to_file(linee, driver='ESRI Shapefile', encoding='utf-8')\n",
        "    try: os.remove(pieghe)\n",
        "    except: pass\n",
        "print('Output in:', output_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "version": "3"}
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CARG GPKG â†’ Shapefile (Open Libraries, Colab-ready)\n",
        "Questo notebook usa solo librerie open (GeoPandas/Fiona/Shapely/pyproj/dbfread) e puÃ² essere eseguito su Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Installa dipendenze (Colab)\n",
        "Esegui se stai lavorando in Colab o in un ambiente pulito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esegui in Colab\n",
        "try:\n",
        "    import geopandas as gpd  # se giÃ  installato, non fa nulla\n",
        "except Exception:\n",
        "    pass\n",
        "!pip -q install geopandas fiona shapely pyproj dbfread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Carica i file (Colab)\n",
        "Carica il GeoPackage (.gpkg) e opzionalmente domini.zip (contenente i .dbf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, time, zipfile\n",
        "from google.colab import files as colab_files\n",
        "uploads = colab_files.upload()  # seleziona .gpkg e (opzionale) domini.zip\n",
        "\n",
        "# Crea workspace locale\n",
        "workspace = '/content/workspace'\n",
        "os.makedirs(workspace, exist_ok=True)\n",
        "\n",
        "gpkg_path = ''\n",
        "for fn in uploads:\n",
        "    src = f'/content/{fn}'\n",
        "    dst = os.path.join(workspace, fn)\n",
        "    os.replace(src, dst)\n",
        "    if fn.lower().endswith('.gpkg'):\n",
        "        gpkg_path = dst\n",
        "    if fn.lower() == 'domini.zip':\n",
        "        with zipfile.ZipFile(dst) as z:\n",
        "            z.extractall(os.path.join(workspace, 'domini'))\n",
        "\n",
        "assert gpkg_path, 'Carica un file .gpkg'\n",
        "domini_dir = os.path.join(workspace, 'domini')\n",
        "print('Workspace:', workspace)\n",
        "print('GPKG:', gpkg_path)\n",
        "print('Domini dir:', domini_dir, 'Exists:', os.path.exists(domini_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Setup e layer disponibili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import fiona\n",
        "from dbfread import DBF\n",
        "\n",
        "output_dir = os.path.join(workspace, 'output')\n",
        "try:\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    test = os.path.join(output_dir, f'.write_test_{int(time.time())}')\n",
        "    with open(test, 'w', encoding='utf-8') as f: f.write('ok')\n",
        "    os.remove(test)\n",
        "except Exception:\n",
        "    ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "    output_dir = os.path.join(workspace, f'output_{ts}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "layers = fiona.listlayers(gpkg_path)\n",
        "print('Output dir:', output_dir)\n",
        "print('Layer disponibili:', layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Funzioni di supporto (domini, salvataggio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_domain_dbf(path, code_field='CODE', desc_pattern='DESC'):\n",
        "    if not os.path.exists(path):\n",
        "        return {}\n",
        "    try:\n",
        "        recs = list(DBF(path, encoding='utf-8', ignore_missing_memofile=True))\n",
        "        if not recs:\n",
        "            return {}\n",
        "        desc_field = None\n",
        "        for k in recs[0].keys():\n",
        "            if desc_pattern.upper() in k.upper():\n",
        "                desc_field = k; break\n",
        "        if not desc_field or code_field not in recs[0]:\n",
        "            return {}\n",
        "        m = {}\n",
        "        for r in recs:\n",
        "            c = r.get(code_field); d = r.get(desc_field)\n",
        "            if c is None or d is None: continue\n",
        "            d = str(d).strip()\n",
        "            m[str(c).strip()] = d\n",
        "            if isinstance(c, (int, float)):\n",
        "                m[c] = d\n",
        "        return m\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def apply_domain(df, src_col, out_col, mapping):\n",
        "    if not mapping:\n",
        "        df[out_col] = ''\n",
        "        return df\n",
        "    def map_val(v):\n",
        "        if pd.isna(v): return ''\n",
        "        return mapping.get(v, mapping.get(str(v).strip(), ''))\n",
        "    df[out_col] = df[src_col].apply(map_val) if src_col in df.columns else ''\n",
        "    return df\n",
        "\n",
        "def ensure_text_len(df, cols, maxlen=254):\n",
        "    for c in cols:\n",
        "        if c in df.columns: df[c] = df[c].astype(str).str.slice(0, maxlen)\n",
        "    return df\n",
        "\n",
        "def save_shp(gdf, path):\n",
        "    drop_cols = [c for c in gdf.columns if c.upper().startswith('SHAPE_')]\n",
        "    gdf = gdf.drop(columns=drop_cols, errors='ignore')\n",
        "    gdf.to_file(path, driver='ESRI Shapefile', encoding='utf-8')\n",
        "    return path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Estrai Foglio e domini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "foglio = None\n",
        "for ln in layers:\n",
        "    try:\n",
        "        g = gpd.read_file(gpkg_path, layer=ln)\n",
        "        if 'FoglioGeologico' in g.columns:\n",
        "            v = g['FoglioGeologico'].dropna().astype(str).str.strip()\n",
        "            if not v.empty:\n",
        "                foglio = v.iloc[0]; break\n",
        "    except Exception:\n",
        "        pass\n",
        "assert foglio is not None, 'FoglioGeologico non trovato'\n",
        "foglio_map = load_domain_dbf(os.path.join(domini_dir,'d_foglio.dbf'), code_field='N1', desc_pattern='N2')\n",
        "foglio_txt = foglio_map.get(foglio, foglio)\n",
        "print('Foglio:', foglio, 'â†’', foglio_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Configurazioni e conversione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "configs = {\n",
        " 'ST010Point': { 'search':['ST010Point','main.ST010Point'], 'output':'geomorfologia_punti.shp',\n",
        "   'fields': {'Pun_Gmo':'Pun_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_10_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n",
        " 'ST011Polygon': { 'search':['ST011Polygon','main.ST011Polygon'], 'output':'geomorfologia_poligoni.shp',\n",
        "   'fields': {'Pol_Gmo':'Pol_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_11_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n",
        " 'ST012Polyline': { 'search':['ST012Polyline','main.ST012Polyline'], 'output':'geomorfologia_linee.shp',\n",
        "   'fields': {'Lin_Gmo':'Lin_Gmo','Label':'Label','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_12_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n",
        " 'ST013Point': { 'search':['ST013Point','main.ST013Point'], 'output':'risorse_prospezioni.shp',\n",
        "   'fields': {'Num_Ris':'Num_Ris','Label1':'Label1','Label2':'Label2','Label3':'Label3','TIPO':'Tipo'},\n",
        "   'domains': {'Tipo': ('d_13_tipo.dbf','Tipo_txt')} },\n",
        " 'ST018Polyline': { 'search':['ST018Polyline','main.ST018Polyline'], 'output':'geologia_linee.shp',\n",
        "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Contorno':'Contorno','Affiora':'Affiora','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_geo': ('d_st018_line.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Contorno':('d_st018_contorno.dbf','Cont_txt'),'Affiora':('d_st018_affiora.dbf','Affior_txt')},\n",
        "   'extra_fixed': {'Fase_txt':'non applicabile/non classificabile'} },\n",
        " 'ST018Polygon': { 'search':['ST018Polygon','main.ST018Polygon'], 'output':'geologia_poligoni.shp',\n",
        "   'fields': {'Pol_Uc':'Pol_Uc','Uc_Lege':'Uc_Lege','Direzio':'Direzione'}, 'domains': {} },\n",
        " 'ST019Point': { 'search':['ST019Point','main.ST019Point'], 'output':'geologia_punti.shp',\n",
        "   'fields': {'Num_Oss':'Num_Oss','Quota':'Quota','Inclina':'Inclinaz','Immersio':'Immersione','Direzio':'Direzione','Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Verso':'Verso','Asimmetria':'Asimmetria'},\n",
        "   'domains': {'Tipo_geo': ('d_19_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt'),'Verso':('d_verso.dbf','Verso_txt'),'Asimmetria':('d_asimmetria.dbf','Asimm_txt')} },\n",
        " 'ST021Polyline': { 'search':['ST021Polyline','main.ST021Polyline'], 'output':'geologia_linee_pieghe.shp',\n",
        "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_geo': ('d_st021.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt')},\n",
        "   'extra_fixed': {'Affior_txt':'non applicabile','Cont_txt':'no'} }\n",
        "}\n",
        "\n",
        "def find_layer(name_variants):\n",
        "    for nv in name_variants:\n",
        "        if nv in layers: return nv\n",
        "    for nv in name_variants:\n",
        "        for L in layers:\n",
        "            if nv.lower() in L.lower(): return L\n",
        "    return None\n",
        "\n",
        "def process_one(cfg):\n",
        "    ln = find_layer(cfg['search'])\n",
        "    if not ln: return False\n",
        "    g = gpd.read_file(gpkg_path, layer=ln)\n",
        "    out = pd.DataFrame(index=g.index)\n",
        "    for src,dst in cfg['fields'].items(): out[dst] = g[src] if src in g.columns else ''\n",
        "    for k,v in cfg.get('extra_fixed',{}).items(): out[k]=v\n",
        "    out['Foglio'] = foglio_txt\n",
        "    for src,(domfile,target) in cfg.get('domains',{}).items():\n",
        "        dom = load_domain_dbf(os.path.join(domini_dir, domfile))\n",
        "        mapped_src = cfg['fields'].get(src, src)\n",
        "        if mapped_src in out.columns: out = apply_domain(out, mapped_src, target, dom)\n",
        "    g_out = gpd.GeoDataFrame(out, geometry=g.geometry, crs=g.crs)\n",
        "    g_out = ensure_text_len(g_out, [c for c in g_out.columns if c!='geometry'])\n",
        "    g_out.to_file(os.path.join(output_dir, cfg['output']), driver='ESRI Shapefile', encoding='utf-8')\n",
        "    return True\n",
        "\n",
        "processed = 0\n",
        "for k,cfg in configs.items():\n",
        "    if process_one(cfg): processed += 1\n",
        "print('Layer processati:', processed)\n",
        "\n",
        "# Append pieghe alle linee\n",
        "pieghe = os.path.join(output_dir, 'geologia_linee_pieghe.shp')\n",
        "linee = os.path.join(output_dir, 'geologia_linee.shp')\n",
        "if os.path.exists(pieghe) and os.path.exists(linee):\n",
        "    gL = gpd.read_file(linee)\n",
        "    gP = gpd.read_file(pieghe)\n",
        "    gM = pd.concat([gL, gP], ignore_index=True)\n",
        "    gM.to_file(linee, driver='ESRI Shapefile', encoding='utf-8')\n",
        "    try: os.remove(pieghe)\n",
        "    except: pass\n",
        "print('Output in:', output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Scarica i risultati (Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprimi la cartella di output e scarica\n",
        "import shutil\n",
        "from google.colab import files as colab_files\n",
        "zip_base = '/content/output'\n",
        "shutil.make_archive(zip_base, 'zip', output_dir)\n",
        "colab_files.download(zip_base + '.zip')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "version": "3"}
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CARG GPKG â†’ Shapefile (Open Libraries, Colab-ready)\n",
        "Questo notebook usa solo librerie open (GeoPandas/Fiona/Shapely/pyproj/dbfread) e puÃ² essere eseguito su Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Installa dipendenze (Colab)\n",
        "Esegui se stai lavorando in Colab o in un ambiente pulito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esegui in Colab\n",
        "try:\n",
        "    import geopandas as gpd  # se giÃ  installato, non fa nulla\n",
        "except Exception:\n",
        "    pass\n",
        "!pip -q install geopandas fiona shapely pyproj dbfread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Carica i file (Colab)\n",
        "Carica il GeoPackage (.gpkg) e opzionalmente domini.zip (contenente i .dbf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, time, zipfile\n",
        "from google.colab import files as colab_files\n",
        "uploads = colab_files.upload()  # seleziona .gpkg e (opzionale) domini.zip\n",
        "\n",
        "# Crea workspace locale\n",
        "workspace = '/content/workspace'\n",
        "os.makedirs(workspace, exist_ok=True)\n",
        "\n",
        "gpkg_path = ''\n",
        "for fn in uploads:\n",
        "    src = f'/content/{fn}'\n",
        "    dst = os.path.join(workspace, fn)\n",
        "    os.replace(src, dst)\n",
        "    if fn.lower().endswith('.gpkg'):\n",
        "        gpkg_path = dst\n",
        "    if fn.lower() == 'domini.zip':\n",
        "        with zipfile.ZipFile(dst) as z:\n",
        "            z.extractall(os.path.join(workspace, 'domini'))\n",
        "\n",
        "assert gpkg_path, 'Carica un file .gpkg'\n",
        "domini_dir = os.path.join(workspace, 'domini')\n",
        "print('Workspace:', workspace)\n",
        "print('GPKG:', gpkg_path)\n",
        "print('Domini dir:', domini_dir, 'Exists:', os.path.exists(domini_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Setup e layer disponibili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import fiona\n",
        "from dbfread import DBF\n",
        "\n",
        "output_dir = os.path.join(workspace, 'output')\n",
        "try:\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    test = os.path.join(output_dir, f'.write_test_{int(time.time())}')\n",
        "    with open(test, 'w', encoding='utf-8') as f: f.write('ok')\n",
        "    os.remove(test)\n",
        "except Exception:\n",
        "    ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "    output_dir = os.path.join(workspace, f'output_{ts}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "layers = fiona.listlayers(gpkg_path)\n",
        "print('Output dir:', output_dir)\n",
        "print('Layer disponibili:', layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Funzioni di supporto (domini, salvataggio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_domain_dbf(path, code_field='CODE', desc_pattern='DESC'):\n",
        "    if not os.path.exists(path):\n",
        "        return {}\n",
        "    try:\n",
        "        recs = list(DBF(path, encoding='utf-8', ignore_missing_memofile=True))\n",
        "        if not recs:\n",
        "            return {}\n",
        "        desc_field = None\n",
        "        for k in recs[0].keys():\n",
        "            if desc_pattern.upper() in k.upper():\n",
        "                desc_field = k; break\n",
        "        if not desc_field or code_field not in recs[0]:\n",
        "            return {}\n",
        "        m = {}\n",
        "        for r in recs:\n",
        "            c = r.get(code_field); d = r.get(desc_field)\n",
        "            if c is None or d is None: continue\n",
        "            d = str(d).strip()\n",
        "            m[str(c).strip()] = d\n",
        "            if isinstance(c, (int, float)):\n",
        "                m[c] = d\n",
        "        return m\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def apply_domain(df, src_col, out_col, mapping):\n",
        "    if not mapping:\n",
        "        df[out_col] = ''\n",
        "        return df\n",
        "    def map_val(v):\n",
        "        if pd.isna(v): return ''\n",
        "        return mapping.get(v, mapping.get(str(v).strip(), ''))\n",
        "    df[out_col] = df[src_col].apply(map_val) if src_col in df.columns else ''\n",
        "    return df\n",
        "\n",
        "def ensure_text_len(df, cols, maxlen=254):\n",
        "    for c in cols:\n",
        "        if c in df.columns: df[c] = df[c].astype(str).str.slice(0, maxlen)\n",
        "    return df\n",
        "\n",
        "def save_shp(gdf, path):\n",
        "    drop_cols = [c for c in gdf.columns if c.upper().startswith('SHAPE_')]\n",
        "    gdf = gdf.drop(columns=drop_cols, errors='ignore')\n",
        "    gdf.to_file(path, driver='ESRI Shapefile', encoding='utf-8')\n",
        "    return path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Estrai Foglio e domini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "foglio = None\n",
        "for ln in layers:\n",
        "    try:\n",
        "        g = gpd.read_file(gpkg_path, layer=ln)\n",
        "        if 'FoglioGeologico' in g.columns:\n",
        "            v = g['FoglioGeologico'].dropna().astype(str).str.strip()\n",
        "            if not v.empty:\n",
        "                foglio = v.iloc[0]; break\n",
        "    except Exception:\n",
        "        pass\n",
        "assert foglio is not None, 'FoglioGeologico non trovato'\n",
        "foglio_map = load_domain_dbf(os.path.join(domini_dir,'d_foglio.dbf'), code_field='N1', desc_pattern='N2')\n",
        "foglio_txt = foglio_map.get(foglio, foglio)\n",
        "print('Foglio:', foglio, 'â†’', foglio_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Configurazioni e conversione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "configs = {\n",
        " 'ST010Point': { 'search':['ST010Point','main.ST010Point'], 'output':'geomorfologia_punti.shp',\n",
        "   'fields': {'Pun_Gmo':'Pun_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_10_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n",
        " 'ST011Polygon': { 'search':['ST011Polygon','main.ST011Polygon'], 'output':'geomorfologia_poligoni.shp',\n",
        "   'fields': {'Pol_Gmo':'Pol_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_11_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n",
        " 'ST012Polyline': { 'search':['ST012Polyline','main.ST012Polyline'], 'output':'geomorfologia_linee.shp',\n",
        "   'fields': {'Lin_Gmo':'Lin_Gmo','Label':'Label','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato'},\n",
        "   'domains': {'Tipo_Gmrf': ('d_12_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n",
        " 'ST013Point': { 'search':['ST013Point','main.ST013Point'], 'output':'risorse_prospezioni.shp',\n",
        "   'fields': {'Num_Ris':'Num_Ris','Label1':'Label1','Label2':'Label2','Label3':'Label3','TIPO':'Tipo'},\n",
        "   'domains': {'Tipo': ('d_13_tipo.dbf','Tipo_txt')} },\n",
        " 'ST018Polyline': { 'search':['ST018Polyline','main.ST018Polyline'], 'output':'geologia_linee.shp',\n",
        "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Contorno':'Contorno','Affiora':'Affiora','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_geo': ('d_st018_line.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Contorno':('d_st018_contorno.dbf','Cont_txt'),'Affiora':('d_st018_affiora.dbf','Affior_txt')},\n",
        "   'extra_fixed': {'Fase_txt':'non applicabile/non classificabile'} },\n",
        " 'ST018Polygon': { 'search':['ST018Polygon','main.ST018Polygon'], 'output':'geologia_poligoni.shp',\n",
        "   'fields': {'Pol_Uc':'Pol_Uc','Uc_Lege':'Uc_Lege','Direzio':'Direzione'}, 'domains': {} },\n",
        " 'ST019Point': { 'search':['ST019Point','main.ST019Point'], 'output':'geologia_punti.shp',\n",
        "   'fields': {'Num_Oss':'Num_Oss','Quota':'Quota','Inclina':'Inclinaz','Immersio':'Immersione','Direzio':'Direzione','Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Verso':'Verso','Asimmetria':'Asimmetria'},\n",
        "   'domains': {'Tipo_geo': ('d_19_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt'),'Verso':('d_verso.dbf','Verso_txt'),'Asimmetria':('d_asimmetria.dbf','Asimm_txt')} },\n",
        " 'ST021Polyline': { 'search':['ST021Polyline','main.ST021Polyline'], 'output':'geologia_linee_pieghe.shp',\n",
        "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Direzio':'Direzione'},\n",
        "   'domains': {'Tipo_geo': ('d_st021.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt')},\n",
        "   'extra_fixed': {'Affior_txt':'non applicabile','Cont_txt':'no'} }\n",
        "}\n",
        "\n",
        "def find_layer(name_variants):\n",
        "    for nv in name_variants:\n",
        "        if nv in layers: return nv\n",
        "    for nv in name_variants:\n",
        "        for L in layers:\n",
        "            if nv.lower() in L.lower(): return L\n",
        "    return None\n",
        "\n",
        "def process_one(cfg):\n",
        "    ln = find_layer(cfg['search'])\n",
        "    if not ln: return False\n",
        "    g = gpd.read_file(gpkg_path, layer=ln)\n",
        "    out = pd.DataFrame(index=g.index)\n",
        "    for src,dst in cfg['fields'].items(): out[dst] = g[src] if src in g.columns else ''\n",
        "    for k,v in cfg.get('extra_fixed',{}).items(): out[k]=v\n",
        "    out['Foglio'] = foglio_txt\n",
        "    for src,(domfile,target) in cfg.get('domains',{}).items():\n",
        "        dom = load_domain_dbf(os.path.join(domini_dir, domfile))\n",
        "        mapped_src = cfg['fields'].get(src, src)\n",
        "        if mapped_src in out.columns: out = apply_domain(out, mapped_src, target, dom)\n",
        "    g_out = gpd.GeoDataFrame(out, geometry=g.geometry, crs=g.crs)\n",
        "    g_out = ensure_text_len(g_out, [c for c in g_out.columns if c!='geometry'])\n",
        "    g_out.to_file(os.path.join(output_dir, cfg['output']), driver='ESRI Shapefile', encoding='utf-8')\n",
        "    return True\n",
        "\n",
        "processed = 0\n",
        "for k,cfg in configs.items():\n",
        "    if process_one(cfg): processed += 1\n",
        "print('Layer processati:', processed)\n",
        "\n",
        "# Append pieghe alle linee\n",
        "pieghe = os.path.join(output_dir, 'geologia_linee_pieghe.shp')\n",
        "linee = os.path.join(output_dir, 'geologia_linee.shp')\n",
        "if os.path.exists(pieghe) and os.path.exists(linee):\n",
        "    gL = gpd.read_file(linee)\n",
        "    gP = gpd.read_file(pieghe)\n",
        "    gM = pd.concat([gL, gP], ignore_index=True)\n",
        "    gM.to_file(linee, driver='ESRI Shapefile', encoding='utf-8')\n",
        "    try: os.remove(pieghe)\n",
        "    except: pass\n",
        "print('Output in:', output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Scarica i risultati (Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprimi la cartella di output e scarica\n",
        "import shutil\n",
        "from google.colab import files as colab_files\n",
        "zip_base = '/content/output'\n",
        "shutil.make_archive(zip_base, 'zip', output_dir)\n",
        "colab_files.download(zip_base + '.zip')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "version": "3"}
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
