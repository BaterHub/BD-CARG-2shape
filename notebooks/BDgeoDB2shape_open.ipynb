{
  "cells": [
    {"cell_type": "markdown", "metadata": {}, "source": ["# CARG FileGDB → Shapefile (Open Libraries)\n", "Esegui questo notebook con GeoPandas/Fiona/Shapely/pyproj/dbfread.\n", "\n", "Nota: la lettura .gdb usa il driver OpenFileGDB (read-only), sufficiente per esportare in shapefile."]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## Requisiti\n", "```bash\n", "pip install geopandas fiona shapely pyproj dbfread\n", "```"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os, time, re\n", "import pandas as pd\n", "import geopandas as gpd\n", "import fiona\n", "from dbfread import DBF\n", "\n", "gdb_path = r'C:\\path\\to\\your\\data.gdb'  # MODIFICA QUI (cartella .gdb)\n", "workspace = os.path.dirname(os.path.abspath(gdb_path)) if gdb_path else os.getcwd()\n", "domini_dir = os.path.join(workspace, 'domini')\n", "output_dir = os.path.join(workspace, 'output')\n", "\n", "try:\n", "    os.makedirs(output_dir, exist_ok=True)\n", "    test = os.path.join(output_dir, f'.write_test_{int(time.time())}')\n", "    with open(test, 'w', encoding='utf-8') as f: f.write('ok')\n", "    os.remove(test)\n", "except Exception:\n", "    ts = time.strftime('%Y%m%d_%H%M%S')\n", "    output_dir = os.path.join(workspace, f'output_{ts}')\n", "    os.makedirs(output_dir, exist_ok=True)\n", "\n", "print('Output:', output_dir)\n", "layers = fiona.listlayers(gdb_path)\n", "print('Layer disponibili:', layers)\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_domain_dbf(path, code_field='CODE', desc_pattern='DESC'):\n", "    if not os.path.exists(path): return {}\n", "    try:\n", "        recs = list(DBF(path, encoding='utf-8', ignore_missing_memofile=True))\n", "        if not recs: return {}\n", "        desc_field = None\n", "        for k in recs[0].keys():\n", "            if desc_pattern.upper() in k.upper(): desc_field = k; break\n", "        if not desc_field or code_field not in recs[0]: return {}\n", "        m = {}\n", "        for r in recs:\n", "            c, d = r.get(code_field), r.get(desc_field)\n", "            if c is None or d is None: continue\n", "            d = str(d).strip()\n", "            m[str(c).strip()] = d\n", "            if isinstance(c, (int, float)): m[c] = d\n", "        return m\n", "    except Exception:\n", "        return {}\n", "\n", "def apply_domain(df, src_col, out_col, mapping):\n", "    if not mapping:\n", "        df[out_col] = ''\n", "        return df\n", "    def map_val(v):\n", "        if pd.isna(v): return ''\n", "        return mapping.get(v, mapping.get(str(v).strip(), ''))\n", "    df[out_col] = df[src_col].apply(map_val) if src_col in df.columns else ''\n", "    return df\n", "\n", "def ensure_text_len(df, cols, maxlen=254):\n", "    for c in cols:\n", "        if c in df.columns: df[c] = df[c].astype(str).str.slice(0, maxlen)\n", "    return df\n", "\n", "def save_shp(gdf, path):\n", "    drop_cols = [c for c in gdf.columns if c.upper().startswith('SHAPE_')]\n", "    gdf = gdf.drop(columns=drop_cols, errors='ignore')\n", "    gdf.to_file(path, driver='ESRI Shapefile', encoding='utf-8')\n", "    return path\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# FoglioGeologico\n", "foglio = None\n", "for ln in layers:\n", "    try:\n", "        g = gpd.read_file(gdb_path, layer=ln)\n", "        if 'FoglioGeologico' in g.columns:\n", "            v = g['FoglioGeologico'].dropna().astype(str).str.strip()\n", "            if not v.empty: foglio = v.iloc[0]; break\n", "    except Exception: pass\n", "assert foglio is not None, 'FoglioGeologico non trovato'\n", "print('Foglio:', foglio)\n", "foglio_map = load_domain_dbf(os.path.join(domini_dir,'d_foglio.dbf'), code_field='N1', desc_pattern='N2')\n", "foglio_txt = foglio_map.get(foglio, foglio)\n", "print('Foglio (mappato):', foglio_txt)\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["configs = {\n", " 'ST010Point': { 'search':['ST010Point','main.ST010Point','main/ST010Point'], 'output':'geomorfologia_punti.shp',\n", "   'fields': {'Pun_Gmo':'Pun_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n", "   'domains': {'Tipo_Gmrf': ('d_10_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n", " 'ST011Polygon': { 'search':['ST011Polygon','main.ST011Polygon','main/ST011Polygon'], 'output':'geomorfologia_poligoni.shp',\n", "   'fields': {'Pol_Gmo':'Pol_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n", "   'domains': {'Tipo_Gmrf': ('d_11_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n", " 'ST012Polyline': { 'search':['ST012Polyline','main.ST012Polyline','main/ST012Polyline'], 'output':'geomorfologia_linee.shp',\n", "   'fields': {'Lin_Gmo':'Lin_Gmo','Label':'Label','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato'},\n", "   'domains': {'Tipo_Gmrf': ('d_12_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n", " 'ST013Point': { 'search':['ST013Point','main.ST013Point','main/ST013Point'], 'output':'risorse_prospezioni.shp',\n", "   'fields': {'Num_Ris':'Num_Ris','Label1':'Label1','Label2':'Label2','Label3':'Label3','TIPO':'Tipo'},\n", "   'domains': {'Tipo': ('d_13_tipo.dbf','Tipo_txt')} },\n", " 'ST018Polyline': { 'search':['ST018Polyline','main.ST018Polyline','main/ST018Polyline'], 'output':'geologia_linee.shp',\n", "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Contorno':'Contorno','Affiora':'Affiora','Direzio':'Direzione'},\n", "   'domains': {'Tipo_geo': ('d_st018_line.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Contorno':('d_st018_contorno.dbf','Cont_txt'),'Affiora':('d_st018_affiora.dbf','Affior_txt')},\n", "   'extra_fixed': {'Fase_txt':'non applicabile/non classificabile'} },\n", " 'ST018Polygon': { 'search':['ST018Polygon','main.ST018Polygon','main/ST018Polygon'], 'output':'geologia_poligoni.shp',\n", "   'fields': {'Pol_Uc':'Pol_Uc','Uc_Lege':'Uc_Lege','Direzio':'Direzione'}, 'domains': {} },\n", " 'ST019Point': { 'search':['ST019Point','main.ST019Point','main/ST019Point'], 'output':'geologia_punti.shp',\n", "   'fields': {'Num_Oss':'Num_Oss','Quota':'Quota','Inclina':'Inclinaz','Immersio':'Immersione','Direzio':'Direzione','Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Verso':'Verso','Asimmetria':'Asimmetria'},\n", "   'domains': {'Tipo_geo': ('d_19_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt'),'Verso':('d_verso.dbf','Verso_txt'),'Asimmetria':('d_asimmetria.dbf','Asimm_txt')} },\n", " 'ST021Polyline': { 'search':['ST021Polyline','main.ST021Polyline','main/ST021Polyline'], 'output':'geologia_linee_pieghe.shp',\n", "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Direzio':'Direzione'},\n", "   'domains': {'Tipo_geo': ('d_st021.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt')},\n", "   'extra_fixed': {'Affior_txt':'non applicabile','Cont_txt':'no'} }\n", "}\n", "\n", "def find_layer(name_variants):\n", "    for nv in name_variants:\n", "        if nv in layers: return nv\n", "    for nv in name_variants:\n", "        for L in layers:\n", "            if nv.lower() in L.lower(): return L\n", "    return None\n", "\n", "def process_one(cfg):\n", "    ln = find_layer(cfg['search'])\n", "    if not ln: return False\n", "    g = gpd.read_file(gdb_path, layer=ln)\n", "    out = pd.DataFrame(index=g.index)\n", "    for src,dst in cfg['fields'].items(): out[dst] = g[src] if src in g.columns else ''\n", "    for k,v in cfg.get('extra_fixed',{}).items(): out[k]=v\n", "    out['Foglio'] = foglio_txt\n", "    for src,(domfile,target) in cfg.get('domains',{}).items():\n", "        dom = load_domain_dbf(os.path.join(domini_dir, domfile))\n", "        mapped_src = cfg['fields'].get(src, src)\n", "        if mapped_src in out.columns: out = apply_domain(out, mapped_src, target, dom)\n", "    g_out = gpd.GeoDataFrame(out, geometry=g.geometry, crs=g.crs)\n", "    g_out = ensure_text_len(g_out, [c for c in g_out.columns if c!='geometry'])\n", "    g_out.to_file(os.path.join(output_dir, cfg['output']), driver='ESRI Shapefile', encoding='utf-8')\n", "    return True\n", "\n", "processed = 0\n", "for k,cfg in configs.items():\n", "    if process_one(cfg): processed += 1\n", "print('Layer processati:', processed)\n", "\n", "pieghe = os.path.join(output_dir, 'geologia_linee_pieghe.shp')\n", "linee = os.path.join(output_dir, 'geologia_linee.shp')\n", "if os.path.exists(pieghe) and os.path.exists(linee):\n", "    gL = gpd.read_file(linee)\n", "    gP = gpd.read_file(pieghe)\n", "    gM = pd.concat([gL, gP], ignore_index=True)\n", "    gM.to_file(linee, driver='ESRI Shapefile', encoding='utf-8')\n", "    try: os.remove(pieghe)\n", "    except: pass\n", "print('Output in:', output_dir)\n"]}
  ],
  "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3"}},
  "nbformat": 4,
  "nbformat_minor": 2
}
{
  "cells": [
    {"cell_type": "markdown", "metadata": {}, "source": ["# CARG FileGDB → Shapefile (Open Libraries, Colab-ready)\n", "Questo notebook usa GeoPandas/Fiona/Shapely/pyproj/dbfread ed è pronto per Colab."]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Installa dipendenze (Colab)"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import geopandas as gpd\n", "except Exception:\n", "    pass\n", "!pip -q install geopandas fiona shapely pyproj dbfread"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Carica i file (Colab)\n", "Carica mydata.gdb.zip (la .gdb compressa) e domini.zip."]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os, time, zipfile\n", "from google.colab import files as colab_files\n", "uploads = colab_files.upload()\n", "workspace = '/content/workspace'\n", "os.makedirs(workspace, exist_ok=True)\n", "gdb_path = ''\n", "for fn in uploads:\n", "    src = f'/content/{fn}'\n", "    dst = os.path.join(workspace, fn)\n", "    os.replace(src, dst)\n", "    if fn.lower().endswith('.zip') and fn.lower().endswith('.gdb.zip') is False and fn.lower()=='domini.zip':\n", "        with zipfile.ZipFile(dst) as z:\n", "            z.extractall(os.path.join(workspace, 'domini'))\n", "    if fn.lower().endswith('.gdb.zip'):\n", "        with zipfile.ZipFile(dst) as z:\n", "            z.extractall(workspace)\n", "        # trova la cartella .gdb estratta\n", "        for root,dirs,files in os.walk(workspace):\n", "            for d in dirs:\n", "                if d.lower().endswith('.gdb'):\n", "                    gdb_path = os.path.join(root,d); break\n", "print('Workspace:', workspace)\n", "print('GDB:', gdb_path)\n", "domini_dir = os.path.join(workspace, 'domini')\n", "print('Domini dir:', domini_dir, 'Exists:', os.path.exists(domini_dir))\n", "assert gdb_path.lower().endswith('.gdb')"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Setup e layer disponibili"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import re, pandas as pd, geopandas as gpd, fiona\n", "from dbfread import DBF\n", "output_dir = os.path.join(workspace, 'output')\n", "try:\n", "    os.makedirs(output_dir, exist_ok=True)\n", "    test = os.path.join(output_dir, f'.write_test_{int(time.time())}')\n", "    with open(test, 'w', encoding='utf-8') as f: f.write('ok')\n", "    os.remove(test)\n", "except Exception:\n", "    ts = time.strftime('%Y%m%d_%H%M%S')\n", "    output_dir = os.path.join(workspace, f'output_{ts}')\n", "    os.makedirs(output_dir, exist_ok=True)\n", "layers = fiona.listlayers(gdb_path)\n", "print('Output dir:', output_dir)\n", "print('Layer disponibili:', layers)"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Funzioni di supporto"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_domain_dbf(path, code_field='CODE', desc_pattern='DESC'):\n", "    if not os.path.exists(path): return {}\n", "    try:\n", "        recs = list(DBF(path, encoding='utf-8', ignore_missing_memofile=True))\n", "        if not recs: return {}\n", "        desc_field = None\n", "        for k in recs[0].keys():\n", "            if desc_pattern.upper() in k.upper(): desc_field = k; break\n", "        if not desc_field or code_field not in recs[0]: return {}\n", "        m = {}\n", "        for r in recs:\n", "            c, d = r.get(code_field), r.get(desc_field)\n", "            if c is None or d is None: continue\n", "            d = str(d).strip()\n", "            m[str(c).strip()] = d\n", "            if isinstance(c, (int, float)): m[c] = d\n", "        return m\n", "    except Exception:\n", "        return {}\n", "\n", "def apply_domain(df, src_col, out_col, mapping):\n", "    if not mapping:\n", "        df[out_col] = ''\n", "        return df\n", "    def map_val(v):\n", "        if pd.isna(v): return ''\n", "        return mapping.get(v, mapping.get(str(v).strip(), ''))\n", "    df[out_col] = df[src_col].apply(map_val) if src_col in df.columns else ''\n", "    return df\n", "\n", "def ensure_text_len(df, cols, maxlen=254):\n", "    for c in cols:\n", "        if c in df.columns: df[c] = df[c].astype(str).str.slice(0, maxlen)\n", "    return df\n", "\n", "def save_shp(gdf, path):\n", "    drop_cols = [c for c in gdf.columns if c.upper().startswith('SHAPE_')]\n", "    gdf = gdf.drop(columns=drop_cols, errors='ignore')\n", "    gdf.to_file(path, driver='ESRI Shapefile', encoding='utf-8')\n", "    return path\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Estrai Foglio e domini"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["foglio = None\n", "for ln in layers:\n", "    try:\n", "        g = gpd.read_file(gdb_path, layer=ln)\n", "        if 'FoglioGeologico' in g.columns:\n", "            v = g['FoglioGeologico'].dropna().astype(str).str.strip()\n", "            if not v.empty: foglio = v.iloc[0]; break\n", "    except Exception: pass\n", "assert foglio is not None, 'FoglioGeologico non trovato'\n", "foglio_map = load_domain_dbf(os.path.join(domini_dir,'d_foglio.dbf'), code_field='N1', desc_pattern='N2')\n", "foglio_txt = foglio_map.get(foglio, foglio)\n", "print('Foglio:', foglio, '→', foglio_txt)"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Configurazioni e conversione"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["configs = {\n", " 'ST010Point': { 'search':['ST010Point','main.ST010Point','main/ST010Point'], 'output':'geomorfologia_punti.shp',\n", "   'fields': {'Pun_Gmo':'Pun_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n", "   'domains': {'Tipo_Gmrf': ('d_10_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n", " 'ST011Polygon': { 'search':['ST011Polygon','main.ST011Polygon','main/ST011Polygon'], 'output':'geomorfologia_poligoni.shp',\n", "   'fields': {'Pol_Gmo':'Pol_Gmo','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato','Direzio':'Direzione'},\n", "   'domains': {'Tipo_Gmrf': ('d_11_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n", " 'ST012Polyline': { 'search':['ST012Polyline','main.ST012Polyline','main/ST012Polyline'], 'output':'geomorfologia_linee.shp',\n", "   'fields': {'Lin_Gmo':'Lin_Gmo','Label':'Label','Tipo':'Tipo_Gmrf','Tipologia':'Tipologia','Stato':'Stato'},\n", "   'domains': {'Tipo_Gmrf': ('d_12_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Stato':('d_stato.dbf','Stato_txt')} },\n", " 'ST013Point': { 'search':['ST013Point','main.ST013Point','main/ST013Point'], 'output':'risorse_prospezioni.shp',\n", "   'fields': {'Num_Ris':'Num_Ris','Label1':'Label1','Label2':'Label2','Label3':'Label3','TIPO':'Tipo'},\n", "   'domains': {'Tipo': ('d_13_tipo.dbf','Tipo_txt')} },\n", " 'ST018Polyline': { 'search':['ST018Polyline','main.ST018Polyline','main/ST018Polyline'], 'output':'geologia_linee.shp',\n", "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Contorno':'Contorno','Affiora':'Affiora','Direzio':'Direzione'},\n", "   'domains': {'Tipo_geo': ('d_st018_line.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Contorno':('d_st018_contorno.dbf','Cont_txt'),'Affiora':('d_st018_affiora.dbf','Affior_txt')},\n", "   'extra_fixed': {'Fase_txt':'non applicabile/non classificabile'} },\n", " 'ST018Polygon': { 'search':['ST018Polygon','main.ST018Polygon','main/ST018Polygon'], 'output':'geologia_poligoni.shp',\n", "   'fields': {'Pol_Uc':'Pol_Uc','Uc_Lege':'Uc_Lege','Direzio':'Direzione'}, 'domains': {} },\n", " 'ST019Point': { 'search':['ST019Point','main.ST019Point','main/ST019Point'], 'output':'geologia_punti.shp',\n", "   'fields': {'Num_Oss':'Num_Oss','Quota':'Quota','Inclina':'Inclinaz','Immersio':'Immersione','Direzio':'Direzione','Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Verso':'Verso','Asimmetria':'Asimmetria'},\n", "   'domains': {'Tipo_geo': ('d_19_tipo.dbf','Tipo_G_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt'),'Verso':('d_verso.dbf','Verso_txt'),'Asimmetria':('d_asimmetria.dbf','Asimm_txt')} },\n", " 'ST021Polyline': { 'search':['ST021Polyline','main.ST021Polyline','main/ST021Polyline'], 'output':'geologia_linee_pieghe.shp',\n", "   'fields': {'Tipo':'Tipo_geo','Tipologia':'Tipologia','Fase':'Fase','Direzio':'Direzione'},\n", "   'domains': {'Tipo_geo': ('d_st021.dbf','Tipo_g_txt'),'Tipologia':('d_tipologia.dbf','Tipol_txt'),'Fase':('d_fase.dbf','Fase_txt')},\n", "   'extra_fixed': {'Affior_txt':'non applicabile','Cont_txt':'no'} }\n", "}\n", "\n", "def find_layer(name_variants):\n", "    for nv in name_variants:\n", "        if nv in layers: return nv\n", "    for nv in name_variants:\n", "        for L in layers:\n", "            if nv.lower() in L.lower(): return L\n", "    return None\n", "\n", "def process_one(cfg):\n", "    ln = find_layer(cfg['search'])\n", "    if not ln: return False\n", "    g = gpd.read_file(gdb_path, layer=ln)\n", "    out = pd.DataFrame(index=g.index)\n", "    for src,dst in cfg['fields'].items(): out[dst] = g[src] if src in g.columns else ''\n", "    for k,v in cfg.get('extra_fixed',{}).items(): out[k]=v\n", "    out['Foglio'] = foglio_txt\n", "    for src,(domfile,target) in cfg.get('domains',{}).items():\n", "        dom = load_domain_dbf(os.path.join(domini_dir, domfile))\n", "        mapped_src = cfg['fields'].get(src, src)\n", "        if mapped_src in out.columns: out = apply_domain(out, mapped_src, target, dom)\n", "    g_out = gpd.GeoDataFrame(out, geometry=g.geometry, crs=g.crs)\n", "    g_out = ensure_text_len(g_out, [c for c in g_out.columns if c!='geometry'])\n", "    g_out.to_file(os.path.join(output_dir, cfg['output']), driver='ESRI Shapefile', encoding='utf-8')\n", "    return True\n", "\n", "processed = 0\n", "for k,cfg in configs.items():\n", "    if process_one(cfg): processed += 1\n", "print('Layer processati:', processed)\n", "\n", "pieghe = os.path.join(output_dir, 'geologia_linee_pieghe.shp')\n", "linee = os.path.join(output_dir, 'geologia_linee.shp')\n", "if os.path.exists(pieghe) and os.path.exists(linee):\n", "    gL = gpd.read_file(linee)\n", "    gP = gpd.read_file(pieghe)\n", "    gM = pd.concat([gL, gP], ignore_index=True)\n", "    gM.to_file(linee, driver='ESRI Shapefile', encoding='utf-8')\n", "    try: os.remove(pieghe)\n", "    except: pass\n", "print('Output in:', output_dir)"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## 7) Scarica i risultati (Colab)"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import shutil\n", "from google.colab import files as colab_files\n", "zip_base = '/content/output'\n", "shutil.make_archive(zip_base, 'zip', output_dir)\n", "colab_files.download(zip_base + '.zip')"]}
  ],
  "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3"}},
  "nbformat": 4,
  "nbformat_minor": 2
}
